{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">Machine Learning</font><a class=\"anchor\"><a id='toc'></a></b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='54C13C'>3rd Individual Assignment</font> <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "    \n",
    "### Student Name:\n",
    "Sofia Alexandra Grifo Cunha\n",
    "### Student Number:\n",
    "M20190795 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"54C13C\"> Company Dataset </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `Employee_ID`: The unique identifier of the employee\\\n",
    " `Gender`: The gender of the employee\\\n",
    " `Age`: The age (in years) of the employee\\\n",
    " `Days_off`:  Number of days the employee took off over the last year\\\n",
    " `Rotations`: Number of team changes the employee made\\\n",
    " `Satis_leader`: Level of satisfaction with the leadership\\\n",
    " `Satis_team`: Level of satisfaction with the team\\\n",
    " `Emails`: Average number of received emails in a day\\\n",
    " `Tenure`: Number years the employee has been working for the company\\\n",
    " `Bonus`: Bonus received as percentage of salary\\\n",
    " `Distance`: Distance from home to the workplace\\\n",
    "`Kids`: Number of kids\\\n",
    " `Overtime`: Average number of overtime hours a month\\\n",
    " `Marital_status`: Marital status of the employee\\\n",
    " `Department`: Department of the employee\\\n",
    " `Churn_risk`: Churn risk level of the employee\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\"> Imports </font> <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     KFold,\n",
    "                                     GridSearchCV)\n",
    "from sklearn.preprocessing import (Normalizer,\n",
    "                                   MinMaxScaler,\n",
    "                                   LabelEncoder,\n",
    "                                   RobustScaler,\n",
    "                                   StandardScaler)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\"> Functions </font> <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model):\n",
    "    kf = KFold(n_splits=10)\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    timer = []\n",
    "    for train_index, test_index in kf.split(X_company):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        begin = time.perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        end = time.perf_counter()\n",
    "        value_train = model.score(X_train, y_train)\n",
    "        value_test = model.score(X_test,y_test)\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        timer.append(end-begin)\n",
    "\n",
    "    avg_time = round(np.mean(timer),3)\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_test = round(np.mean(score_test),3)\n",
    "    std_time = round(np.std(timer),2)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_test = round(np.std(score_test),2)\n",
    "    \n",
    "    return str(avg_time) + '+/-' + str(std_time), str(avg_train) + '+/-' + str(std_train),\\\n",
    "str(avg_test) + '+/-' + str(std_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "def plot_tree(model):\n",
    "    dot_data = export_graphviz(model,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               class_names=[\"Low\", \"Medium\", \"High\"],\n",
    "                               filled=True)\n",
    "    pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    pydot_graph.set_size('\"20,20\"')\n",
    "    return graphviz.Source(pydot_graph.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Age(data): \n",
    "    data['Age'] = pd.cut(data['Age'], bins=[0, 19, 29, 39, 49, 59, 99], labels=[0, 1, 2, 3, 4, 5])\n",
    "    data['Age'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(df, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for arg in args:\n",
    "        # obtain the results provided by avg_score\n",
    "        time, avg_train, avg_test = avg_score(arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = time, avg_train, avg_test\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"54C13C\"> Train Set </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\">  Data Understanding </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the dataset train to build my model. Then I create an objectsnamed __company__ that contains the dataset __train.csv__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\"> Transformations </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that we cant scalle categorical variables, I decided to replace the categories, so this variable transforms into a numerical one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "company['Churn_risk'] = company['Churn_risk'].replace('low', 0)\n",
    "company['Churn_risk'] = company['Churn_risk'].replace('medium', 1)\n",
    "company['Churn_risk'] = company['Churn_risk'].replace('high', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employee_ID       0\n",
       "Gender            0\n",
       "Age               9\n",
       "Days_off          8\n",
       "Rotations         2\n",
       "Satis_leader      2\n",
       "Satis_team        1\n",
       "Emails            0\n",
       "Tenure            0\n",
       "Bonus             0\n",
       "Distance          9\n",
       "Kids              4\n",
       "Overtime          0\n",
       "Marital_status    0\n",
       "Department        0\n",
       "Churn_risk        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysing the missing values that exist in the dataset, I replace them by 0 and by the mean to slove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company.loc[company.Days_off.isnull(), 'Days_off'] = 0\n",
    "company.loc[company.Rotations.isnull(), 'Rotations'] =0\n",
    "company.loc[company.Kids.isnull(), 'Kids'] = 0\n",
    "company.loc[company.Distance.isnull(), 'Distance'] = company.Distance.mean()\n",
    "company.loc[company.Age.isnull(), 'Age'] = company.Age.mean()\n",
    "company.loc[company.Satis_leader.isnull(), 'Satis_leader'] = company.Satis_leader.mean()\n",
    "company.loc[company.Satis_team.isnull(), 'Satis_team'] = company.Satis_team.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gender`, `Department`and `Marital_status`are categorical variables, so in a way to solve this problem for the futher analysis, my solution was to transform into dummys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['Gender','Department', 'Marital_status']\n",
    "new_categoricals = [col for col in categoricals if col in company.columns]\n",
    "\n",
    "company = pd.get_dummies(data=company, columns=new_categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "company['Age'] = company['Age'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = company.loc[company['Days_off']<0]\n",
    "out = out.append(company.loc[company['Days_off']>24])\n",
    "out = out.append(company.loc[company['Age']>=68])\n",
    "out = out.append(company.loc[company['Satis_leader']>5])\n",
    "out = out.append(company.loc[company['Satis_team']>8])\n",
    "out = out.append(company.loc[company['Emails']>120])\n",
    "out = out.append(company.loc[company['Tenure']>35])\n",
    "out = out.append(company.loc[company['Bonus']>2])\n",
    "out = out.append(company.loc[company['Distance']>4])\n",
    "out = out.append(company.loc[company['Overtime']>14])\n",
    "company = company.loc[~company['Employee_ID'].isin(out['Employee_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "company.set_index('Employee_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create an object named __X_company__ that will contain the independent variables and another object named __y_company__ that will contains the independent varaible. And it was used the train_test_slipt method to slipt the data into the train and test sets. The divison was with 80% of the data to build the model, and 20% to evaluate the performance of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_company= company.drop(['Churn_risk'], axis = 1)\n",
    "y_company = company['Churn_risk']\n",
    "\n",
    "X_train_company, X_test_company, y_train_company, y_test_company= train_test_split(X_company, y_company,\n",
    "                                                                                   test_size = 0.2, random_state = 15,\n",
    "                                                                                   stratify = y_company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"54C13C\"> Decision Tree Model </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier**: I create an instace of DecisionTreeClassifie named DTmodel. And after I use the .fit()method of model to fit the model to the array of points X_train_company and y_train_company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTmodel= DecisionTreeClassifier(ccp_alpha=0.0007622811970638056, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features=None,\n",
    "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                       min_impurity_split=None, min_samples_leaf=1,\n",
    "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                       presort='deprecated', random_state=0, splitter='best').fit(X_train_company, y_train_company).fit(X_train_company, y_train_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181159420289855"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTmodel.score(X_train_company, y_train_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7393822393822393"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTmodel.score(X_test_company, y_test_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67       379\n",
      "           1       0.77      0.81      0.79       625\n",
      "           2       0.67      0.12      0.21        32\n",
      "\n",
      "    accuracy                           0.74      1036\n",
      "   macro avg       0.71      0.54      0.56      1036\n",
      "weighted avg       0.74      0.74      0.73      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictDT= DTmodel.predict(X_test_company)\n",
    "print (classification_report (y_test_company, predictDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7316190305265563\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test_company, predictDT, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Result:__ To evaluate my model I had in account the value from the score, where I got 0.74, and the F1_score where the result was 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"54C13C\"> Test Set </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the test to see how well my model performs on unseen data. Then I create one objects named __testcompany__ which contains the dataset __test.csv__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcompany = pd.DataFrame(pd.read_csv(\"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\"> Transformations </font> <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = testcompany.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.set_index('Employee_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**: After analysing the missing values that exist in the dataset, I replace them by 0 and bt the mean to slove this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.loc[tc.Days_off.isnull(), 'Days_off'] = 0\n",
    "tc.loc[tc.Satis_team.isnull(), 'Satis_team'] =tc.Satis_team.mean()\n",
    "tc.loc[tc.Age.isnull(), 'Age'] = tc.Age.mean() \n",
    "tc.loc[tc.Rotations.isnull(), 'Rotations'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gender`, `Department`and `Marital_status`are categorical variables, so in a way to solve this problem for the futher analysis, my solution was to transform into dummys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['Gender','Department', 'Marital_status']\n",
    "new_categoricals = [col for col in categoricals if col in tc.columns]\n",
    "\n",
    "tc = pd.get_dummies(data=tc, columns=new_categoricals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\"> Test prediction </font> <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the train results of my model, the next step was to predict it in the test dataset, wich after the transformations is named __tc__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = DTmodel.predict(tc)\n",
    "predict= pd.DataFrame()\n",
    "predict['Employee_ID']= testcompany['Employee_ID'].copy()\n",
    "predict['Churn_risk']= prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict['Churn_risk'] = predict['Churn_risk'].replace(0, 'low')\n",
    "predict['Churn_risk'] = predict['Churn_risk'].replace(1, 'medium')\n",
    "predict['Churn_risk'] = predict['Churn_risk'].replace(2, 'high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Churn_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005201</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005202</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005203</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005204</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005205</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1006496</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1006497</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1006498</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1006499</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1006500</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Employee_ID Churn_risk\n",
       "0         1005201        low\n",
       "1         1005202     medium\n",
       "2         1005203        low\n",
       "3         1005204     medium\n",
       "4         1005205     medium\n",
       "...           ...        ...\n",
       "1295      1006496     medium\n",
       "1296      1006497     medium\n",
       "1297      1006498        low\n",
       "1298      1006499     medium\n",
       "1299      1006500     medium\n",
       "\n",
       "[1300 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"54C13C\"> Export .csv file </font> <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.to_csv('M20190795_DTversion18.csv',index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
